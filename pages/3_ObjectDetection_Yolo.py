import streamlit as st
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase
from ultralytics import YOLO
import av
import cv2

st.set_page_config(page_title="Nháº­n dáº¡ng Ä‘á»‘i tÆ°á»£ng - YOLOv8", layout="centered")
st.title("ðŸŽ¯ Nháº­n dáº¡ng Ä‘á»‘i tÆ°á»£ng báº±ng YOLOv8")

# Chá»n mÃ´ hÃ¬nh YOLO
model_type = st.selectbox("Chá»n mÃ´ hÃ¬nh YOLO", ['yolov8n.pt', 'yolov8s.pt', 'yolov8m.pt', 'yolov8l.pt', 'yolov8x.pt'])
model = YOLO(model_type)

# Chá»n nguá»“n
source_type = st.radio("Nguá»“n dá»¯ liá»‡u", ['Webcam', 'Táº£i áº£nh'])

# ======================= Xá»¬ LÃ áº¢NH ======================
if source_type == 'Táº£i áº£nh':
    uploaded_file = st.file_uploader("ðŸ“ Táº£i áº£nh lÃªn", type=["jpg", "jpeg", "png"])
    if uploaded_file is not None:
        file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
        image = cv2.imdecode(file_bytes, 1)

        results = model(image, verbose=False)[0]
        annotated_image = results.plot()

        st.image(annotated_image, channels="BGR", caption="ðŸ–¼ï¸ Káº¿t quáº£ nháº­n dáº¡ng")

# ===================== Xá»¬ LÃ WEBCAM =====================
else:
    class YOLOTransformer(VideoTransformerBase):
        def transform(self, frame: av.VideoFrame) -> av.VideoFrame:
            img = frame.to_ndarray(format="bgr24")

            results = model(img, verbose=False)[0]
            annotated = results.plot()

            return av.VideoFrame.from_ndarray(annotated, format="bgr24")

    webrtc_streamer(key="yolo", video_transformer_factory=YOLOTransformer, media_stream_constraints={"video": True, "audio": False})
